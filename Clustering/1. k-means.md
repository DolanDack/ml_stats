In this chapter we will work on the k-means algorithm. We will base our analysis on the Information Theory, Inference, and Learning Algorithms. 
The k-means clustering is an algorithm for putting N data points in an I-dimensional space into K-clusters. The algorithm has one parameter for each cluster.
The algorithm is an iterative one, where first step is to randomly assign clusters in the data space. Then we assign each data point to a specific cluster depending on the distance between them.
Then, we calculate the mean of the data points that belong to a cluster. We do that by using a distance metric...for example Euclidean distance. We iterate through the steps until we can no longer update the mean parameters. 

We can prove of the efficiency of k-means and that it will always converge by showing that there exists an associated Lyapunov function.

Some drawbacks of the k-means are:
1. The k-means does not take into account the size, shape or weight of each data point into a cluster. A way to address this is by introducing soft k-means. 